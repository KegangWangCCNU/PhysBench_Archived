{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoobHeart's JAX implementation  \n",
    "\n",
    "PhysBench does not rely on any deep learning framework, it handles all preprocessing, postprocessing, visualization, and then exposes the core model development completely to users who can flexibly choose their own development tools.  \n",
    "\n",
    "### Preparation  \n",
    "\n",
    "First, you need to prepare the dataset and training data. Please refer to `Noob Heart.ipynb`, this part is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, lax\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the convolutional kernel weights of NoobHeart and define the model structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoobHeart(seeds=jax.random.PRNGKey(range(6))):\n",
    "    weights = [\n",
    "        jax.random.normal(seeds[0], (4, 3, 2, 2, 2,)),  # kernel 1\n",
    "        jax.random.normal(seeds[1], (4, 1, 1, 1)),      # basis  1\n",
    "        jax.random.normal(seeds[2], (2, 4, 2, 2, 2,)),  # kernel 2\n",
    "        jax.random.normal(seeds[3], (2, 1, 1, 1)),      # basis  2\n",
    "        jax.random.normal(seeds[4], (1, 1, 1, 1, 1,)),  # kernel 3\n",
    "        jax.random.normal(seeds[5], (1, 1, 1, 1)),      # basis  3\n",
    "    ]\n",
    "    N = lambda x, ax=2:(x-jnp.expand_dims(x.mean(axis=ax), ax))/jnp.expand_dims(x.std(axis=ax), ax)\n",
    "    @jit\n",
    "    def model(x, weights=weights):\n",
    "        x = N(jnp.transpose(x, (0, 4, 1, 2, 3)))                                # BCDHW\n",
    "        x = N(lax.tanh(lax.conv(x, weights[0], (1, 2, 2), 'SAME')+weights[1]))  # Conv Tanh Norm\n",
    "        x = N(lax.tanh(lax.conv(x, weights[2], (1, 2, 2), 'SAME')+weights[3]))\n",
    "        x = lax.conv(x, jnp.ones((1, 2, 1, 2, 2)), (1, 2, 2), 'VALID')          # Pool\n",
    "        x = lax.conv(x, weights[4], (1, 1, 1), 'SAME')+weights[5]\n",
    "        return x.reshape(x.shape[0], -1)                                        # Flatten\n",
    "    model.weights = weights\n",
    "    return model\n",
    "\n",
    "model = NoobHeart()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0,\tval_loss=0.6488630175590515\n",
      "Best model checked\n",
      "epoch=1,\tval_loss=0.6216443777084351\n",
      "Best model checked\n",
      "epoch=2,\tval_loss=0.602000892162323\n",
      "Best model checked\n",
      "epoch=3,\tval_loss=0.5860676169395447\n",
      "Best model checked\n",
      "epoch=4,\tval_loss=0.5778675079345703\n",
      "Best model checked\n",
      "epoch=5,\tval_loss=0.5712727308273315\n",
      "Best model checked\n",
      "epoch=6,\tval_loss=0.5722319483757019\n",
      "epoch=7,\tval_loss=0.5705991387367249\n",
      "Best model checked\n",
      "epoch=8,\tval_loss=0.5706881880760193\n",
      "epoch=9,\tval_loss=0.5693888664245605\n",
      "Best model checked\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "train = load_datatape(\"train_tape.h5\", batch=batch) # Training set\n",
    "valid = load_datatape(\"valid_tape.h5\", batch=batch) # Validation set\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(0.01) # Adam optimizer\n",
    "opt_state = opt_init(model.weights)\n",
    "\n",
    "best = None\n",
    "for epoch in range(10): # 10 epochs\n",
    "    for step, (data, label) in enumerate(train): # train\n",
    "        loss = lambda weights: jnp.mean(abs((model(data, weights)-label)))\n",
    "        grads = grad(loss)(get_params(opt_state))\n",
    "        opt_state = opt_update(step, grads, opt_state)\n",
    "    vloss = []\n",
    "    for step, (data, label) in enumerate(valid): # val\n",
    "        vloss.append(jnp.mean(abs((model(data, get_params(opt_state))-label))))\n",
    "    vloss = jnp.mean(jnp.stack(vloss))\n",
    "    print(f'{epoch=},\\tval_loss={vloss}')\n",
    "    if best is None or best[1]>vloss:\n",
    "        best = opt_state, vloss\n",
    "        print('Best model checked')\n",
    "        \n",
    "for i, j in enumerate(get_params(best[0])): # load the best\n",
    "    model.weights[i] = j\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `eval_on_dataset` to test and obtain metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0db07e1ac244124b91dd20d5ec682ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR metrics: MAE:1.009, RMSE:1.433, R:0.9969\n",
      "HRV metrics: MAE:38.703, RMSE:43.339, R:0.62763\n"
     ]
    }
   ],
   "source": [
    "eval_on_dataset('ubfc_dataset.h5', model, 32, (8, 8), step=1, batch=32, ipt_dtype=np.float32, save='../results/NoobHeart_PURE_UBFC.h5')\n",
    "r = get_metrics('../results/NoobHeart_PURE_UBFC.h5')['Whole video']\n",
    "print(f'HR metrics: MAE:{r[\"MAE\"]}, RMSE:{r[\"RMSE\"]}, R:{r[\"R\"]}')\n",
    "r = get_metrics_HRV('../results/NoobHeart_PURE_UBFC.h5')['SDNN']\n",
    "print(f'HRV metrics: MAE:{r[\"MAE\"]}, RMSE:{r[\"RMSE\"]}, R:{r[\"R\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
