{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "from models_torch import *\n",
    "import torch.optim as optim\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tape = \"Z:/rppg/ubfc_datatape_160x128x128_train.h5\"\n",
    "valid_tape = \"Z:/rppg/ubfc_datatape_160x128x128_valid.h5\"\n",
    "\n",
    "train =  load_datatape(train_tape, use_normalized_bvp=True)\n",
    "valid = load_datatape(valid_tape, use_normalized_bvp=False)\n",
    "\n",
    "def RandomHorizontalFlip(data, label, p=.5):\n",
    "    if np.random.random()<p:\n",
    "        return data[..., ::-1 ,:], label\n",
    "    return data, label\n",
    "\n",
    "def data_loader(tape, batch_size=4, shuffle_size=2000):\n",
    "    shuffle_size = max(batch_size, shuffle_size)\n",
    "    buff = []\n",
    "    for i in tape:\n",
    "        i = [i.astype(np.float16) for i in i]\n",
    "        if not 40<get_hr(i[1])<179:\n",
    "            continue\n",
    "        buff.append(RandomHorizontalFlip(*i))\n",
    "        if len(buff)>=shuffle_size:\n",
    "            shuffle(buff)\n",
    "            batch = [buff.pop(0) for _ in range(batch_size)]\n",
    "            yield torch.tensor(np.array([i[0][..., [2, 1, 0]].transpose(3, 0, 1, 2) for i in batch])).float()*2-1, torch.tensor(np.array([i[1] for i in batch]))\n",
    "    while len(buff)>=batch_size:\n",
    "        shuffle(buff)\n",
    "        batch = [buff.pop(0) for _ in range(batch_size)]\n",
    "        yield torch.tensor(np.array([i[0][..., [2, 1, 0]].transpose(3, 0, 1, 2) for i in batch])).float()*2-1, torch.tensor(np.array([i[1] for i in batch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gra_sharp = 2.\n",
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,128,128), patches=(4,4,4), dim=96, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7).cuda()\n",
    "lr=0.0001\n",
    "step_size = 50\n",
    "batch_size=4\n",
    "optimizer1 = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00005)\n",
    "scheduler1 = optim.lr_scheduler.StepLR(optimizer1, step_size=step_size, gamma=0.5)\n",
    "\n",
    "criterion_Pearson = Neg_Pearson()\n",
    "valid_baches = 1000\n",
    "\n",
    "# a --> Pearson loss; b --> frequency loss\n",
    "a_start = 0.1\n",
    "b_start = 1\n",
    "exp_b = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 train:\n",
      "Test RMSE:9.892, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.9782, b=1.000, kl= 3.5053, fre_CEloss= 4.9240, hr_mae= 16.7771\n",
      "Best model saved\n",
      "epoch:1 train:\n",
      "Test RMSE:4.676, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.7009, b=1.175, kl= 3.4827, fre_CEloss= 4.9012, hr_mae= 2.4957\n",
      "Best model saved\n",
      "epoch:2 train:\n",
      "Test RMSE:4.051, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.6070, b=1.380, kl= 3.4798, fre_CEloss= 4.8983, hr_mae= 1.8244\n",
      "Best model saved\n",
      "epoch:3 train:\n",
      "Test RMSE:2.812, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.5586, b=1.621, kl= 3.4785, fre_CEloss= 4.8970, hr_mae= 1.5864\n",
      "Best model saved\n",
      "epoch:4 train:\n",
      "Test RMSE:4.330, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.5238, b=1.904, kl= 3.4778, fre_CEloss= 4.8963, hr_mae= 1.6439\n",
      "epoch:5 train:\n",
      "Test RMSE:2.665, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.4934, b=2.236, kl= 3.4772, fre_CEloss= 4.8957, hr_mae= 1.3808\n",
      "Best model saved\n",
      "epoch:6 train:\n",
      "Test RMSE:2.606, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.4781, b=2.627, kl= 3.4767, fre_CEloss= 4.8952, hr_mae= 1.3187\n",
      "Best model saved\n",
      "epoch:7 train:\n",
      "Test RMSE:4.356, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.4697, b=3.085, kl= 3.4765, fre_CEloss= 4.8949, hr_mae= 1.3628\n",
      "epoch:8 train:\n",
      "Test RMSE:3.438, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.4507, b=3.624, kl= 3.4761, fre_CEloss= 4.8945, hr_mae= 1.2715\n",
      "epoch:9 train:\n",
      "Test RMSE:4.337, batch:121121, lr=0.000100, sharp=2.000, a=0.100, NegPearson= 0.4421, b=4.257, kl= 3.4760, fre_CEloss= 4.8944, hr_mae= 1.2793\n"
     ]
    }
   ],
   "source": [
    "best = np.inf\n",
    "for epoch in range(10):\n",
    "    loss_rPPG_avg = []\n",
    "    loss_peak_avg = []\n",
    "    loss_kl_avg_test = []\n",
    "    loss_hr_mae = []\n",
    "    model.train()\n",
    "    fps = 30\n",
    "    print(f'epoch:{epoch} train:')\n",
    "    for i, (data, label) in enumerate(data_loader(train, batch_size=batch_size)):\n",
    "        hr = torch.tensor([get_hr(i) for i in label]).float().cuda()\n",
    "        data, label = data.float().cuda(), label.float().cuda()\n",
    "        optimizer1.zero_grad()\n",
    "        bvp, s1, s2, s3 = model(data, gra_sharp)\n",
    "        bvp = (bvp-torch.mean(bvp, axis=-1).view(-1, 1))/torch.std(bvp, axis=-1).view(-1, 1)\n",
    "        loss_bvp = criterion_Pearson(bvp, label)\n",
    "        fre_loss = .0\n",
    "        kl = .0\n",
    "        train_mae = .0\n",
    "        for bb in range(data.shape[0]):\n",
    "            loss_distribution_kl, fre_loss_temp, train_mae_temp = cross_entropy_power_spectrum_DLDL_softmax2(bvp[bb], hr[bb], fps, std=1.0)\n",
    "            fre_loss = fre_loss+fre_loss_temp\n",
    "            kl = kl+loss_distribution_kl\n",
    "            train_mae = train_mae+train_mae_temp\n",
    "        fre_loss /= data.shape[0]\n",
    "        kl /= data.shape[0]\n",
    "        train_mae /= data.shape[0]\n",
    "        a = a_start\n",
    "        if epoch>10:\n",
    "            b = b_start*exp_b\n",
    "        else:\n",
    "            b = b_start*exp_b**(epoch/10)\n",
    "        loss = a*loss_bvp + b*(fre_loss+kl)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        n = data.size(0)\n",
    "        loss_rPPG_avg.append(float(loss_bvp.data))\n",
    "        loss_peak_avg.append(float(fre_loss.data))\n",
    "        loss_kl_avg_test.append(float(kl.data))\n",
    "        loss_hr_mae.append(float(train_mae))\n",
    "        print('epoch:%d, batch:%d, total=%d, lr=%f, sharp=%.3f, a=%.3f, NegPearson= %.4f, b=%.3f, kl= %.4f, fre_CEloss= %.4f, hr_mae= %.4f' % (epoch, i + 1, len(train)//batch_size, lr, gra_sharp, a, np.mean(loss_rPPG_avg[-2000:]), b, np.mean(loss_kl_avg_test[-2000:]), np.mean(loss_peak_avg[-2000:]), np.mean(loss_hr_mae[-2000:])), end='\\r')\n",
    "    optimizer1.zero_grad()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hrs = []\n",
    "        for j, (data, label) in enumerate(data_loader(valid, batch_size=4)):\n",
    "            data, label = data.cuda().float(), label.cuda().float()\n",
    "            bvp, s1, s2, s3 = model(data, gra_sharp)\n",
    "            bvp = (bvp-torch.mean(bvp, axis=-1).view(-1, 1))/torch.std(bvp).view(-1, 1)\n",
    "            for _1, _2 in zip(bvp, label):\n",
    "                hrs.append((get_hr(_1.cpu().detach().numpy()), get_hr(_2.cpu().detach().numpy())))\n",
    "        RMSE = np.mean([(i-j)**2 for i, j in hrs])**0.5\n",
    "        print(f'Test RMSE:{RMSE:.3f}, batch:{i+1}')\n",
    "        if RMSE<best:\n",
    "            best = RMSE\n",
    "            torch.save(model.state_dict(), '../weights/Physformer_UBFC.pkl')\n",
    "            print('Best model saved')\n",
    "        scheduler1.step()\n",
    "        if (epoch + 1) % step_size == 0:\n",
    "            lr *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../weights/Physformer_UBFC.pkl'))\n",
    "model.train()\n",
    "def physformer(x, model=model):\n",
    "    with torch.no_grad():\n",
    "        bvp = model(torch.tensor(x[..., [2, 1, 0]].transpose(0, 4, 1, 2, 3)).cuda().float()*2-1, gra_sharp)[0].cpu().detach().numpy()\n",
    "        #bvp[:,:30] = bvp[:,130:] = bvp[:, 30:130].mean(axis=-1).reshape(-1, 1)\n",
    "        return bvp - bvp.mean(axis=-1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [05:00<00:00,  5.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sliding window': {'MAE': 18.504, 'RMSE': 30.313, 'R': 0.34842},\n",
       " 'Whole video': {'MAE': 17.603, 'RMSE': 29.024, 'R': 0.39774}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_on_dataset(test_set_PURE, physformer, 160, (128, 128), step=2, batch=4, save='../results/PhysFormer_UBFC_PURE.h5', sample=cv2.INTER_CUBIC)\n",
    "get_metrics('../results/PhysFormer_UBFC_PURE.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
